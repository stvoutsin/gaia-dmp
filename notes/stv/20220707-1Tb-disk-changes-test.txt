#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#



    Target:

        Test deployment with the 1TB disk  changes

    Result:

        Success



# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler2 \
        --hostname ansibler \
        --publish 3001:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.03.19 \
        bash
        
        
        
# -----------------------------------------------------
# Set the target configuration.
#[root@ansibler]

    cloudbase='arcus'
    cloudname='iris-gaia-red'
    configname=zeppelin-54.86-spark-6.26.43


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >  Done



# -----------------------------------------------------
# Create everything.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-all.log
 

# -----------------------------------------------------
# Add the ssh key for our data node.
# This is used by the getpasshash function in the client container.
#[root@ansibler]

    ssh-keyscan 'data.aglais.uk' >> "${HOME}/.ssh/known_hosts"
    


# -----------------------------------------------------
# Create our shiro-auth database.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-auth-database.sh \
            "${cloudname:?}" \
            "${configname:?}" \
        | tee /tmp/create-auth-database.log

        > Done



# -----------------------------------------------------
# Copy notebooks from the live server.
#[root@ansibler]


     ssh zeppelin \
        '
        sshuser=fedora
        sshhost=data.aglais.uk

        sudo mkdir -p '/var/local/backups'
        sudo mv "/home/fedora/zeppelin/notebook" \
           "/var/local/backups/notebook-$(date '+%Y%m%d%H%M%S')"


        rsync \
            --perms \
            --times \
            --group \
            --owner \
            --stats \
            --progress \
            --human-readable \
            --checksum \
            --recursive \
            "${sshuser:?}@${sshhost:?}://var/local/backups/notebook/" \
            "/home/fedora/zeppelin/notebook"
        '
        


# -----------------------------------------------------
# Restart Zeppelin
#[root@ansibler]

    ssh zeppelin \
        '
        zeppelin-daemon.sh restart
        '


# -----------------------------------------------------
# Delete users, so that we can recreate them
    ssh zeppelin 'sudo userdel -r stv'
    ssh zeppelin 'sudo userdel -r zrq'
    ssh zeppelin 'sudo userdel -r nch'
    ssh zeppelin 'sudo userdel -r dcr'
	
# -----------------------------------------------------
# Create users

source /deployments/zeppelin/bin/create-user-tools.sh

createusermain \
        "stv" "admin" \
    | jq '.'
    
{
  "linuxuser": {
    "name": "stv",
    "type": "admin",
    "home": "/home/stv",
    "uid": 20001
  },
  "shirouser": {
    "name": "stv",
    "type": "admin",
    "pass": "",
    "hash": ""
  },
  "hdfsspace": {
    "path": "/albert/stv",
    "owner": "stv",
    "group": "supergroup"
  },
  "notebooks": {}
}


createusermain \
        "zrq" "admin" \
    | jq '.'
{
  "linuxuser": {
    "name": "zrq",
    "type": "admin",
    "home": "/home/zrq",
    "uid": 20002
  },
  "shirouser": {
    "name": "zrq",
    "type": "admin",
    "pass": "",
    "hash": ""
  },
  "hdfsspace": {
    "path": "/albert/zrq",
    "owner": "zrq",
    "group": "supergroup"
  },
  "notebooks": {}
}


createusermain \
        "nch" "admin" \
    | jq '.'
{
  "linuxuser": {
    "name": "nch",
    "type": "admin",
    "home": "/home/nch",
    "uid": 20003
  },
  "shirouser": {
    "name": "nch",
    "type": "admin",
    "pass": "",
    "hash": ""
  },
  "hdfsspace": {
    "path": "/albert/nch",
    "owner": "nch",
    "group": "supergroup"
  },
  "notebooks": {}
}


createusermain \
        "dcr" "user" \
    | jq '.' 
    
{
  "linuxuser": {
    "name": "dcr",
    "type": "user",
    "home": "/home/dcr",
    "uid": 20004
  },
  "shirouser": {
    "name": "dcr",
    "type": "user",
    "pass": "",
    "hash": ""
  },
  "hdfsspace": {
    "path": "/albert/dcr",
    "owner": "dcr",
    "group": "supergroup"
  },
  "notebooks": {}
}


# -----------------------------------------------------	
# Create GDR3 directory

sudo mkdir /data/gaia/GDR3
pushd /data/gaia/GDR3
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_ASTROPHYSICAL_PARAMETERS                     GDR3_ASTROPHYSICAL_PARAMETERS
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_EPOCH_PHOTOMETRY                     GDR3_EPOCH_PHOTOMETRY
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_RVS_MEAN_SPECTRUM                     GDR3_RVS_MEAN_SPECTRUM
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_XP_SAMPLED_MEAN_SPECTRUM                     GDR3_XP_SAMPLED_MEAN_SPECTRUM
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_ASTROPHYSICAL_PARAMETERS_SUPP                     GDR3_ASTROPHYSICAL_PARAMETERS_SUPP
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_XP_CONTINUOUS_MEAN_SPECTRUM                     GDR3_XP_CONTINUOUS_MEAN_SPECTRUM
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_XP_SUMMARY                     GDR3_XP_SUMMARY
    sudo ln -s /user/nch/PARQUET/GDR3/GDR3_GAIA_SOURCE                  GDR3_GAIA_SOURCE
popd


# -----------------------------------------------------	
# Test & Validate user login & Spark job via UI
# Success

# Test simple Spark notebook (Source Count)
# Success

  

# -----------------------------------------------------
# Create 3 test users
#[root@ansibler]

    count=3

    testernames=()

    for i in $(seq $((count+1)))
    do
        testernames+=($(pwgen 12 1))
    done

    createarrayusers \
        ${testernames[@]} \
    | tee /tmp/testusers.json \
    | jq '[ .users[].shirouser.name ]'

# Success



# -----------------------------------------------------
# Run Quick Tests
# Defaults for notebook deletion(True) & timeouts(0)
#[root@ansibler]

    num_users=1
    concurrent=False
    test_level=quick
    cloudname=iris-gaia-red
    configname=zeppelin-26.43-spark-6.26.43



    time \
        /deployments/hadoop-yarn/bin/run-tests.sh \
            "${cloudname:?}" \
            "${configname:?}" \
            "${test_level:?}"  \
	     ${concurrent:?}  \
	     ${num_users:?}  \
        | tee /tmp/run-tests-quick.log
	
	# Cancel and run again for better output..
	
# -----------------------------------------------------
# Run single user test
# Users: 1
# Delay_start: 0
# Delay_notebook: 0
# Delete Notebooks: True


cat > /tmp/testprog.py << EOF
import sys
from aglais_benchmark import AglaisBenchmarker
AglaisBenchmarker(
    "/deployments/zeppelin/test/config/quick.json",
    "/tmp/testusers.json",
    "/tmp/",
    "http://128.232.227.154:8080",
    False
    ).run(
        concurrent=False,
        users=1,
        delay_start=0,
        delay_notebook=0,
        delete=True
        )
EOF

python3 /tmp/testprog.py | tee /tmp/test-results.txt
[{
	"name": "GaiaDMPSetup",
	"result": "PASS",
	"outputs": {
		"valid": true
	},
	"messages": [],
	"time": {
		"result": "FAST",
		"elapsed": "34.53",
		"expected": "45.00",
		"percent": "-23.26",
		"start": "2022-07-07T17:26:43.393542",
		"finish": "2022-07-07T17:27:17.924496"
	},
	"logs": ""
}, {
	"name": "Mean_proper_motions_over_the_sky",
	"result": "PASS",
	"outputs": {
		"valid": true
	},
	"messages": [],
	"time": {
		"result": "SLOW",
		"elapsed": "60.20",
		"expected": "55.00",
		"percent": "9.46",
		"start": "2022-07-07T17:27:17.924581",
		"finish": "2022-07-07T17:28:18.128474"
	},
	"logs": ""
}, {
	"name": "Source_counts_over_the_sky.json",
	"result": "PASS",
	"outputs": {
		"valid": true
	},
	"messages": [],
	"time": {
		"result": "FAST",
		"elapsed": "17.83",
		"expected": "22.00",
		"percent": "-18.94",
		"start": "2022-07-07T17:28:18.128902",
		"finish": "2022-07-07T17:28:35.961038"
	},
	"logs": ""
}, {
	"name": "Library_Validation.json",
	"result": "PASS",
	"outputs": {
		"valid": true
	},
	"messages": [],
	"time": {
		"result": "FAST",
		"elapsed": "8.94",
		"expected": "60.00",
		"percent": "-85.10",
		"start": "2022-07-07T17:28:35.961293",
		"finish": "2022-07-07T17:28:44.902908"
	},
	"logs": ""
}]
